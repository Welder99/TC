# Tech Challenge ‚Äì LSTM para Previs√£o de Pre√ßo de A√ß√µes

Projeto desenvolvido para o **Tech Challenge ‚Äì Fase 4 (Deep Learning e IA)**, com o objetivo de:

> Criar um modelo preditivo utilizando **redes neurais LSTM (Long Short-Term Memory)** para prever o **valor de fechamento** de a√ß√µes de uma empresa, realizando **toda a pipeline**:  
> coleta de dados, pr√©-processamento, treinamento, avalia√ß√£o, salvamento do modelo, deploy em uma **API REST** e configura√ß√£o de monitoramento b√°sico.

---

## üß† Vis√£o Geral do Projeto

Este projeto:

1. **Coleta dados hist√≥ricos de pre√ßos de a√ß√µes** via [Yahoo Finance](https://finance.yahoo.com/) usando a biblioteca `yfinance`.
2. **Pr√©-processa a s√©rie temporal** (normaliza√ß√£o, janelas deslizantes, divis√£o treino/teste).
3. **Treina um modelo LSTM** em Python (TensorFlow/Keras).
4. **Avalia o modelo** usando m√©tricas como **MAE**, **RMSE** e **MAPE**.
5. **Salva o modelo treinado** e o scaler de normaliza√ß√£o em disco.
6. **Exp√µe uma API REST** (FastAPI) que:
   - recebe uma lista de **pre√ßos hist√≥ricos de fechamento**;
   - retorna a **previs√£o do pr√≥ximo pre√ßo de fechamento**.
7. **Exp√µe m√©tricas de monitoramento** no formato Prometheus em `/metrics`.
8. Possui **Dockerfile** para facilitar o deploy em nuvem.

---

## üèó Arquitetura do Projeto

Estrutura de pastas (simplificada):

```txt
.
‚îú‚îÄ‚îÄ pyproject.toml
‚îú‚îÄ‚îÄ uv.lock
‚îú‚îÄ‚îÄ Dockerfile
‚îú‚îÄ‚îÄ artifacts/
‚îÇ   ‚îú‚îÄ‚îÄ lstm_stock.keras      # modelo LSTM treinado
‚îÇ   ‚îî‚îÄ‚îÄ scaler.pkl            # scaler de normaliza√ß√£o (MinMaxScaler)
‚îî‚îÄ‚îÄ src/
    ‚îú‚îÄ‚îÄ __init__.py
    ‚îú‚îÄ‚îÄ config.py             # configura√ß√µes gerais (s√≠mbolo, datas, paths etc.)
    ‚îú‚îÄ‚îÄ data/
    ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
    ‚îÇ   ‚îú‚îÄ‚îÄ download_data.py  # coleta dados do Yahoo Finance
    ‚îÇ   ‚îî‚îÄ‚îÄ preprocess.py     # pr√©-processamento para LSTM
    ‚îú‚îÄ‚îÄ models/
    ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
    ‚îÇ   ‚îú‚îÄ‚îÄ lstm_model.py     # defini√ß√£o da arquitetura LSTM
    ‚îÇ   ‚îú‚îÄ‚îÄ train.py          # script de treinamento e avalia√ß√£o
    ‚îÇ   ‚îî‚îÄ‚îÄ example_predict.py# exemplo de previs√£o direta no console
    ‚îî‚îÄ‚îÄ api/
        ‚îú‚îÄ‚îÄ __init__.py
        ‚îî‚îÄ‚îÄ main.py           # API FastAPI (endpoints /health, /predict, /metrics)


üß∞ Tecnologias Utilizadas

Linguagem: Python 3.12

Gerenciador de ambiente/depend√™ncias: uv

Coleta de dados: yfinance, pandas

Machine Learning / Deep Learning: TensorFlow, Keras, scikit-learn, numpy

API REST: FastAPI, Uvicorn

Monitoramento: prometheus-fastapi-instrumentator (exposi√ß√£o de m√©tricas em /metrics)

Containeriza√ß√£o: Docker

‚öôÔ∏è Configura√ß√£o do Ambiente
1. Clonar o reposit√≥rio
git clone <URL_DO_REPOSITORIO>.git
cd <NOME_DA_PASTA>

2. Instalar o uv (se ainda n√£o tiver)
pip install uv

3. Instalar as depend√™ncias

Na raiz do projeto (onde est√° o pyproject.toml):

uv sync


O uv vai criar/gerenciar o ambiente virtual e instalar as libs necess√°rias.

Sempre que for rodar algo, use uv run ... para garantir que est√° usando o ambiente correto.

üîß Configura√ß√£o da A√ß√£o (S√≠mbolo, Datas, Janela)

No arquivo src/config.py ficam as principais configura√ß√µes:

from pathlib import Path

SYMBOL = "PETR4.SA"  # S√≠mbolo da a√ß√£o (ex.: "PETR4.SA", "VALE3.SA")
START_DATE = "2018-01-01"
END_DATE = "2025-12-09"

WINDOW_SIZE = 5      # quantidade de dias usados como janela de entrada da LSTM
TEST_RATIO = 0.2      # 20% dos dados para teste

BASE_DIR = Path(__file__).resolve().parent.parent
ARTIFACTS_DIR = BASE_DIR / "artifacts"
MODEL_PATH = ARTIFACTS_DIR / "lstm_stock.keras"
SCALER_PATH = ARTIFACTS_DIR / "scaler.pkl"


Voc√™ pode alterar:

SYMBOL para a empresa que o trabalho exigir.

Datas inicial/final, respeitando a disponibilidade no Yahoo Finance.

WINDOW_SIZE (tamanho da janela de entrada da LSTM).

üì• 1. Coleta e Visualiza√ß√£o dos Dados

Para ver os dados hist√≥ricos da a√ß√£o (primeiras/√∫ltimas linhas, estat√≠sticas):

uv run python -m src.data.download_data


Sa√≠da esperada (exemplo):

=== PRIMEIRAS 5 LINHAS (in√≠cio da s√©rie) ===
                 close
Date
2018-01-02   110.55
2018-01-03   111.13
...

=== √öLTIMAS 5 LINHAS (pre√ßos mais recentes) ===
                 close
Date
2024-07-15   102.30
2024-07-16   103.12
...

Total de registros: 1647

=== ESTAT√çSTICAS DA S√âRIE DE PRE√áOS ===
Pre√ßo m√©dio       : 112.34
Pre√ßo m√≠nimo      : 85.12
Pre√ßo m√°ximo      : 154.78


Essa etapa demonstra a coleta via yfinance e uma vis√£o geral da s√©rie.

üß™ 2. Treinamento do Modelo LSTM

O script de treinamento:

Baixa os dados (download_price_data).

Pr√©-processa (normaliza, cria janelas, separa treino/teste).

Constr√≥i o modelo LSTM.

Treina com callbacks (EarlyStopping, ReduceLROnPlateau, ModelCheckpoint).

Avalia nas m√©tricas MAE, RMSE, MAPE.

Salva o modelo e o scaler em artifacts/.

Para treinar:

uv run python -m src.models.train


Ao final, o script imprime algo assim (exemplo ilustrativo):

MAE  : 1.23
RMSE : 1.85
MAPE : 2.10%
Modelo salvo em artifacts/lstm_stock.keras
Scaler salvo em artifacts/scaler.pkl

Interpreta√ß√£o das M√©tricas

MAE (Mean Absolute Error): erro m√©dio absoluto em unidades de pre√ßo
‚Üí ex.: MAE = 1.23 significa erro m√©dio de R$ 1,23.

RMSE (Root Mean Square Error): similar ao MAE, mas penaliza mais erros grandes.

MAPE (Mean Absolute Percentage Error): erro percentual m√©dio
‚Üí ex.: MAPE = 2.10% significa erro m√©dio de ~2,1% em rela√ß√£o ao valor real.

Na documenta√ß√£o do projeto / relat√≥rio, voc√™ pode comentar se esses valores s√£o aceit√°veis considerando a faixa de pre√ßo da a√ß√£o escolhida.

üîç 3. Exemplo de Previs√£o Direta (sem API)

Para testar o modelo diretamente via script (usando os √∫ltimos dados hist√≥ricos da a√ß√£o):

uv run python -m src.models.example_predict


Sa√≠da t√≠pica:

=== √öLTIMOS 10 PRE√áOS REAIS ===
[102.30 103.12 101.80 100.90 102.70 103.40 104.00 103.60 104.20 105.10]

Carregando modelo e scaler...

Usando os √∫ltimos 60 pre√ßos para prever o pr√≥ximo:
1/1 ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 0s 30ms/step

=== RESULTADO DA PREVIS√ÉO ===
Pr√≥ximo pre√ßo de fechamento previsto: 105.87


Esse script √© √∫til para fins de demonstra√ß√£o e valida√ß√£o r√°pida do modelo.

üåê 4. API REST (FastAPI)

A API est√° implementada em src/api/main.py.

4.1. Subir a API
uv run uvicorn src.api.main:app --reload


Se tudo estiver correto, o servidor ir√° rodar em:

http://127.0.0.1:8000

4.2. Endpoints Dispon√≠veis
GET /health

Verifica se a API est√° saud√°vel.

Exemplo de resposta:

{
  "status": "ok"
}

POST /predict

Recebe dados hist√≥ricos de pre√ßos de fechamento e devolve a previs√£o do pr√≥ximo pre√ßo de fechamento.

Request body (JSON):

{
  "closes": [
    100.5,
    101.2,
    99.8,
    102.3,
    103.4,
    ...
  ]
}


O campo closes √© uma lista de valores float (pre√ßos de fechamento em ordem temporal).

√â necess√°rio fornecer pelo menos WINDOW_SIZE valores (configurado em config.py).

Response (JSON):

{
  "next_close": 105.8732
}


Onde next_close √© o pr√≥ximo pre√ßo de fechamento previsto pelo modelo LSTM.

4.3. Testando via Swagger (Interface Gr√°fica)

Com a API rodando, acesse:

http://127.0.0.1:8000/docs

L√° voc√™ pode:

Ver os endpoints (/health, /predict).

Clicar em "Try it out" no /predict.

Enviar um JSON com a lista de closes.

Ver a resposta da previs√£o na pr√≥pria interface web.

4.4. Exemplo de chamada via curl
curl -X 'POST' \
  'http://127.0.0.1:8000/predict' \
  -H 'accept: application/json' \
  -H 'Content-Type: application/json' \
  -d '{
  "closes": [
    100.5, 101.2, 99.8, 102.3, 103.4, 104.0, 103.6, 104.2, 105.1, 104.8,
    105.3, 105.7, 106.1, 105.9, 106.4, 107.0, 107.5, 107.2, 107.9, 108.3,
    108.8, 108.5, 109.0, 109.4, 109.9, 110.3, 110.8, 111.2, 111.7, 112.1,
    112.6, 113.0, 113.5, 113.9, 114.4, 114.8, 115.3, 115.7, 116.2, 116.6,
    117.1, 117.5, 118.0, 118.4, 118.9, 119.3, 119.8, 120.2, 120.7, 121.1,
    121.6, 122.0, 122.5, 122.9, 123.4, 123.8, 124.3, 124.7, 125.2
  ]
}'

üìä 5. Monitoramento (Escalabilidade e Observabilidade)

Para atender ao requisito de escabilidade e monitoramento, a API utiliza:

prometheus-fastapi-instrumentator

No startup da aplica√ß√£o, o instrumentador:

Adiciona middleware para medir:

tempo de resposta,

contagem de requisi√ß√µes,

c√≥digos de status etc.

Exp√µe as m√©tricas em:

GET /metrics

5.1. Acessando m√©tricas

Com a API rodando:

Acesse: http://127.0.0.1:8000/metrics

Voc√™ ver√° um texto em formato Prometheus, com v√°rias m√©tricas que podem ser coletadas num ambiente real por:

Servidor Prometheus

Painel Grafana

Na documenta√ß√£o/relat√≥rio, basta explicar que:

‚ÄúPara monitorar o modelo em produ√ß√£o, a API exp√µe m√©tricas em formato Prometheus no endpoint /metrics, permitindo monitorar tempo de resposta e volume de acessos. Em um ambiente real, essas m√©tricas seriam coletadas por Prometheus e visualizadas em Grafana.‚Äù

üê≥ 6. Docker (Deploy em Container)

O projeto inclui um Dockerfile para facilitar o deploy da API em qualquer ambiente compat√≠vel com Docker (nuvem ou on-premise).

6.1. Build da imagem

Na raiz do projeto:

docker build -t lstm-stock-api .

6.2. Rodar o container
docker run -p 8000:8000 lstm-stock-api


A API ficar√° acess√≠vel em:

http://127.0.0.1:8000

Swagger: http://127.0.0.1:8000/docs

M√©tricas: http://127.0.0.1:8000/metrics

6.3. Deploy em Nuvem (opcional)

Voc√™ pode subir essa imagem em qualquer provedor de nuvem que suporte Docker, por exemplo:

Railway

Render

Fly.io

Azure Container Apps / Web Apps

Google Cloud Run

AWS ECS / Fargate

No relat√≥rio, basta incluir:

Print ou link da API rodando na nuvem (se fizer o deploy).

Breve descri√ß√£o de como o container foi publicado.