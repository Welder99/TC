# Tech Challenge ‚Äì LSTM para Previs√£o de Pre√ßo de A√ß√µes

Projeto desenvolvido para o **Tech Challenge ‚Äì Fase 4 (Deep Learning e IA)**, com o objetivo de:

> Criar um modelo preditivo utilizando **redes neurais LSTM (Long Short-Term Memory)** para prever o **valor de fechamento** de a√ß√µes de uma empresa, realizando **toda a pipeline**:  
> coleta de dados, pr√©-processamento, treinamento, avalia√ß√£o, salvamento do modelo, deploy em uma **API REST** e configura√ß√£o de monitoramento b√°sico.

Neste projeto, a a√ß√£o utilizada foi a **PETR4.SA** (Petrobras PN), com dados hist√≥ricos de **2018-01-01** at√© **2025-12-09**, obtidos via Yahoo Finance.

---

## üß† Vis√£o Geral do Projeto

Este projeto:

1. **Coleta dados hist√≥ricos de pre√ßos de a√ß√µes** via [Yahoo Finance](https://finance.yahoo.com/) usando a biblioteca `yfinance`.
2. **Pr√©-processa a s√©rie temporal** (normaliza√ß√£o, janelas deslizantes, divis√£o treino/teste).
3. **Treina um modelo LSTM** em Python (TensorFlow/Keras).
4. **Avalia o modelo** usando m√©tricas como **MAE**, **RMSE** e **MAPE**.
5. **Salva o modelo treinado** e o scaler de normaliza√ß√£o em disco.
6. **Exp√µe uma API REST** (FastAPI) que:
   - recebe uma lista de **pre√ßos hist√≥ricos de fechamento**;
   - retorna a **previs√£o do pr√≥ximo pre√ßo de fechamento**.
7. **Exp√µe m√©tricas de monitoramento** no formato Prometheus em `/metrics`.
8. Possui **Dockerfile** para facilitar o deploy em nuvem (ex.: AWS EC2).

---

## üèó Arquitetura do Projeto

Estrutura de pastas (simplificada):

```txt
.
‚îú‚îÄ‚îÄ pyproject.toml
‚îú‚îÄ‚îÄ uv.lock
‚îú‚îÄ‚îÄ Dockerfile
‚îú‚îÄ‚îÄ artifacts/
‚îÇ   ‚îú‚îÄ‚îÄ lstm_stock.keras      # modelo LSTM treinado
‚îÇ   ‚îî‚îÄ‚îÄ scaler.pkl            # scaler de normaliza√ß√£o (MinMaxScaler)
‚îî‚îÄ‚îÄ src/
    ‚îú‚îÄ‚îÄ __init__.py
    ‚îú‚îÄ‚îÄ config.py             # configura√ß√µes gerais (s√≠mbolo, datas, paths etc.)
    ‚îú‚îÄ‚îÄ data/
    ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
    ‚îÇ   ‚îú‚îÄ‚îÄ download_data.py  # coleta dados do Yahoo Finance
    ‚îÇ   ‚îî‚îÄ‚îÄ preprocess.py     # pr√©-processamento para LSTM
    ‚îú‚îÄ‚îÄ models/
    ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
    ‚îÇ   ‚îú‚îÄ‚îÄ lstm_model.py     # defini√ß√£o da arquitetura LSTM
    ‚îÇ   ‚îú‚îÄ‚îÄ train.py          # script de treinamento e avalia√ß√£o
    ‚îÇ   ‚îî‚îÄ‚îÄ example_predict.py# exemplo de previs√£o direta no console
    ‚îî‚îÄ‚îÄ api/
        ‚îú‚îÄ‚îÄ __init__.py
        ‚îî‚îÄ‚îÄ main.py           # API FastAPI (endpoints /health, /predict, /metrics)
üß∞ Tecnologias Utilizadas
Linguagem: Python 3.12

Gerenciador de ambiente/depend√™ncias: uv

Coleta de dados: yfinance, pandas

Machine Learning / Deep Learning: TensorFlow, Keras, scikit-learn, numpy

API REST: FastAPI, Uvicorn

Monitoramento: prometheus-fastapi-instrumentator (exposi√ß√£o de m√©tricas em /metrics)

Containeriza√ß√£o: Docker

‚öôÔ∏è Configura√ß√£o do Ambiente
1. Clonar o reposit√≥rio
bash
Copiar c√≥digo
git clone <URL_DO_REPOSITORIO>.git
cd <NOME_DA_PASTA>
(Exemplo: git clone https://github.com/Welder99/TC.git)

2. Instalar o uv (se ainda n√£o tiver)
bash
Copiar c√≥digo
pip install uv
3. Instalar as depend√™ncias
Na raiz do projeto (onde est√° o pyproject.toml):

bash
Copiar c√≥digo
uv sync
O uv vai criar/gerenciar o ambiente virtual e instalar as libs necess√°rias.

Sempre que for rodar algo, use uv run ... para garantir que est√° usando o ambiente correto.

üîß Configura√ß√£o da A√ß√£o (S√≠mbolo, Datas, Janela)
No arquivo src/config.py ficam as principais configura√ß√µes:

python
Copiar c√≥digo
from pathlib import Path

SYMBOL = "PETR4.SA"  # S√≠mbolo da a√ß√£o (ex.: "PETR4.SA", "VALE3.SA")
START_DATE = "2018-01-01"
END_DATE = "2025-12-09"

WINDOW_SIZE = 5       # quantidade de dias usados como janela de entrada da LSTM
TEST_RATIO = 0.2      # 20% dos dados para teste

BASE_DIR = Path(__file__).resolve().parent.parent
ARTIFACTS_DIR = BASE_DIR / "artifacts"
MODEL_PATH = ARTIFACTS_DIR / "lstm_stock.keras"
SCALER_PATH = ARTIFACTS_DIR / "scaler.pkl"
Voc√™ pode alterar:

SYMBOL para outra empresa,

as datas inicial/final, respeitando a disponibilidade no Yahoo Finance,

e o WINDOW_SIZE (tamanho da janela de entrada da LSTM).

üì• 1. Coleta e Visualiza√ß√£o dos Dados
Para ver os dados hist√≥ricos da a√ß√£o (primeiras/√∫ltimas linhas, estat√≠sticas):

bash
Copiar c√≥digo
uv run python -m src.data.download_data
Sa√≠da esperada (exemplo):

text
Copiar c√≥digo
=== PRIMEIRAS 5 LINHAS (in√≠cio da s√©rie) ===
                 close
Date
2018-01-02   110.55
2018-01-03   111.13
...

=== √öLTIMAS 5 LINHAS (pre√ßos mais recentes) ===
                 close
Date
2024-07-15   102.30
2024-07-16   103.12
...

Total de registros: 1647

=== ESTAT√çSTICAS DA S√âRIE DE PRE√áOS ===
Pre√ßo m√©dio       : 112.34
Pre√ßo m√≠nimo      : 85.12
Pre√ßo m√°ximo      : 154.78
Essa etapa demonstra a coleta via yfinance e uma vis√£o geral da s√©rie.

üß™ 2. Treinamento do Modelo LSTM
O script de treinamento:

Baixa os dados (download_price_data).

Pr√©-processa (normaliza, cria janelas, separa treino/teste).

Constr√≥i o modelo LSTM.

Treina com callbacks (EarlyStopping, ReduceLROnPlateau, ModelCheckpoint).

Avalia nas m√©tricas MAE, RMSE, MAPE.

Salva o modelo e o scaler em artifacts/.

Para treinar:

bash
Copiar c√≥digo
uv run python -m src.models.train
No experimento com a a√ß√£o PETR4.SA, o modelo final obteve aproximadamente:

MAE de 0.6318

RMSE de 0.8590

MAPE de 2.01%

Isso significa que, em m√©dia, o erro do modelo √© de cerca de 2% em rela√ß√£o ao pre√ßo real de fechamento.

Ao final, o script informa:

text
Copiar c√≥digo
Modelo salvo em artifacts/lstm_stock.keras
Scaler salvo em artifacts/scaler.pkl
Interpreta√ß√£o das M√©tricas
MAE (Mean Absolute Error): erro m√©dio absoluto em unidades de pre√ßo
‚Üí ex.: MAE = 1.23 significa erro m√©dio de R$ 1,23.

RMSE (Root Mean Square Error): similar ao MAE, mas penaliza mais erros grandes.

MAPE (Mean Absolute Percentage Error): erro percentual m√©dio
‚Üí ex.: MAPE = 2.10% significa erro m√©dio de ~2,1% em rela√ß√£o ao valor real.

Na documenta√ß√£o do projeto / relat√≥rio, pode-se comentar se esses valores s√£o aceit√°veis considerando a faixa de pre√ßo da a√ß√£o escolhida.

üîç 3. Exemplo de Previs√£o Direta (sem API)
Para testar o modelo diretamente via script (usando os √∫ltimos dados hist√≥ricos da a√ß√£o):

bash
Copiar c√≥digo
uv run python -m src.models.example_predict
Sa√≠da t√≠pica:

text
Copiar c√≥digo
=== √öLTIMOS 10 PRE√áOS REAIS ===
[102.30 103.12 101.80 100.90 102.70 103.40 104.00 103.60 104.20 105.10]

Carregando modelo e scaler...

Usando os √∫ltimos WINDOW_SIZE pre√ßos para prever o pr√≥ximo:
1/1 ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 0s 30ms/step

=== RESULTADO DA PREVIS√ÉO ===
Pr√≥ximo pre√ßo de fechamento previsto: 105.87
Esse script √© √∫til para fins de demonstra√ß√£o e valida√ß√£o r√°pida do modelo sem precisar da API.

üåê 4. API REST (FastAPI)
A API est√° implementada em src/api/main.py.

4.1. Subir a API localmente
bash
Copiar c√≥digo
uv run uvicorn src.api.main:app --reload
Se tudo estiver correto, o servidor ir√° rodar em:

text
Copiar c√≥digo
http://127.0.0.1:8000
4.2. Endpoints Dispon√≠veis
GET /health
Verifica se a API est√° saud√°vel.

Exemplo de resposta:

json
Copiar c√≥digo
{
  "status": "ok"
}
POST /predict
Recebe dados hist√≥ricos de pre√ßos de fechamento e devolve a previs√£o do pr√≥ximo pre√ßo de fechamento.

Request body (JSON):

json
Copiar c√≥digo
{
  "closes": [
    100.5,
    101.2,
    99.8,
    102.3,
    103.4
  ]
}
O campo closes √© uma lista de valores float (pre√ßos de fechamento em ordem temporal).

√â necess√°rio fornecer pelo menos WINDOW_SIZE valores (configurado em config.py).

Response (JSON):

json
Copiar c√≥digo
{
  "next_close": 105.8732
}
Onde next_close √© o pr√≥ximo pre√ßo de fechamento previsto pelo modelo LSTM.

4.3. Testando via Swagger (Interface Gr√°fica)
Com a API rodando localmente, acesse:

text
Copiar c√≥digo
http://127.0.0.1:8000/docs
L√° voc√™ pode:

Ver os endpoints (/health, /predict).

Clicar em "Try it out" no /predict.

Enviar um JSON com a lista de closes.

Ver a resposta da previs√£o na pr√≥pria interface web.

4.4. Exemplo de chamada via curl
bash
Copiar c√≥digo
curl -X 'POST' \
  'http://127.0.0.1:8000/predict' \
  -H 'accept: application/json' \
  -H 'Content-Type: application/json' \
  -d '{
  "closes": [
    100.5, 101.2, 99.8, 102.3, 103.4, 104.0, 103.6, 104.2, 105.1, 104.8,
    105.3, 105.7, 106.1, 105.9, 106.4, 107.0, 107.5, 107.2, 107.9, 108.3,
    108.8, 108.5, 109.0, 109.4, 109.9, 110.3, 110.8, 111.2, 111.7, 112.1,
    112.6, 113.0, 113.5, 113.9, 114.4, 114.8, 115.3, 115.7, 116.2, 116.6,
    117.1, 117.5, 118.0, 118.4, 118.9, 119.3, 119.8, 120.2, 120.7, 121.1,
    121.6, 122.0, 122.5, 122.9, 123.4, 123.8, 124.3, 124.7, 125.2
  ]
}'
üìä 5. Monitoramento (Escalabilidade e Observabilidade)
Para atender ao requisito de escabilidade e monitoramento, a API utiliza:

prometheus-fastapi-instrumentator

No startup da aplica√ß√£o, o instrumentador:

Adiciona um middleware para medir:

tempo de resposta,

contagem de requisi√ß√µes,

c√≥digos de status, etc.

Exp√µe as m√©tricas em:

text
Copiar c√≥digo
GET /metrics
5.1. Acessando m√©tricas
Com a API rodando:

text
Copiar c√≥digo
http://127.0.0.1:8000/metrics
Voc√™ ver√° um texto em formato Prometheus, com v√°rias m√©tricas que podem ser coletadas num ambiente real por:

Servidor Prometheus

Painel Grafana

No relat√≥rio, pode-se explicar que:

‚ÄúPara monitorar o modelo em produ√ß√£o, a API exp√µe m√©tricas em formato Prometheus no endpoint /metrics, permitindo monitorar tempo de resposta e volume de acessos. Em um ambiente real, essas m√©tricas seriam coletadas por Prometheus e visualizadas em Grafana.‚Äù

üê≥ 6. Docker (Deploy em Container)
O projeto inclui um Dockerfile para facilitar o deploy da API em qualquer ambiente compat√≠vel com Docker (nuvem ou on-premise).

6.1. Build da imagem
Na raiz do projeto:

bash
Copiar c√≥digo
docker build -t lstm-stock-api .
6.2. Rodar o container localmente
bash
Copiar c√≥digo
docker run -p 8000:8000 lstm-stock-api
A API ficar√° acess√≠vel em:

http://127.0.0.1:8000

Swagger: http://127.0.0.1:8000/docs

M√©tricas: http://127.0.0.1:8000/metrics

6.3. Deploy em Nuvem (exemplos poss√≠veis)
A mesma imagem Docker pode ser usada em qualquer provedor de nuvem que suporte containers, por exemplo:

Railway

Render

Fly.io

Azure Container Apps / Web Apps

Google Cloud Run

AWS ECS / Fargate / EC2

üåç 7. API em Produ√ß√£o (AWS EC2)
Al√©m do ambiente local, a API foi implantada em uma inst√¢ncia AWS EC2 utilizando Docker.

Na EC2 foram feitos os seguintes passos:

Instala√ß√£o do Docker;

Clone do reposit√≥rio a partir do GitHub;

Build da imagem com:

bash
Copiar c√≥digo
docker build -t lstm-stock-api .
Inicializa√ß√£o do container expondo a porta 80:

bash
Copiar c√≥digo
docker run -d --name lstm-stock-api -p 80:8000 lstm-stock-api
Com a porta 80 liberada no Security Group, a API pode ser acessada publicamente em:

Swagger (documenta√ß√£o e testes):
http://18.231.78.59/docs

Healthcheck:
http://18.231.78.59/health

M√©tricas Prometheus:
http://18.231.78.59/metrics

Esse endere√ßo atende ao entreg√°vel do Tech Challenge de ‚Äúlink para a API em produ√ß√£o em ambiente de nuvem‚Äù.